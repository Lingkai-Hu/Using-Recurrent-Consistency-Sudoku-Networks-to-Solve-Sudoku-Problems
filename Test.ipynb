{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.contrib.layers.python.layers import instance_norm\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load Dataset'''\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "'''Normalization Function'''\n",
    "def bn(x):\n",
    "    x=instance_norm(x, epsilon=1e-05)\n",
    "    return x\n",
    "\n",
    "'''Linear Function'''\n",
    "def line(x):\n",
    "    return x\n",
    "\n",
    "'''conv'''\n",
    "def conv(x,filters,kernel_size=3,stride=1,activation=tf.nn.leaky_relu, padding='valid',norm=True,bias=False):\n",
    "    with tf.name_scope('conv'):\n",
    "        x=tf.layers.conv2d(x,filters,kernel_size=kernel_size, strides=stride, padding=padding,use_bias=bias)\n",
    "        if norm:\n",
    "            x=bn(x)\n",
    "            x=activation(x)\n",
    "    return x\n",
    "\n",
    "'''dconv'''\n",
    "def dconv(x,filters,kernel_size=3,stride=1,activation=tf.nn.leaky_relu,padding='valid',norm=True,bias=False):\n",
    "    with tf.name_scope('dconv'):\n",
    "        x=tf.layers.conv2d_transpose(x,filters,kernel_size=kernel_size, strides=stride, padding=padding\n",
    "                                     ,use_bias=bias)\n",
    "        if norm:\n",
    "            x=bn(x)\n",
    "            x=activation(x)\n",
    "    return x\n",
    "\n",
    "'''SDconv'''\n",
    "def sdconv(x,filters,activation=tf.nn.leaky_relu):\n",
    "    x1=conv(x,filters*2,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x2=conv(x,filters*2,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x3=x\n",
    "    x13=dconv(x1,filters*1,kernel_size=[1,1],activation=activation,stride=1)\n",
    "    x23=dconv(x2,filters*1,kernel_size=[1,1],activation=activation,stride=1)\n",
    "    \n",
    "    x11=conv(x1,filters*2,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x12=conv(x1,filters*1,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x21=conv(x2,filters*1,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x22=conv(x2,filters*2,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x12=tf.concat([x12,x21],-1)\n",
    "    x113=dconv(x11,filters*1,kernel_size=[1,1],activation=activation,stride=1)\n",
    "    x123=dconv(x12,filters*1,kernel_size=[1,1],activation=activation,stride=1)\n",
    "    x223=dconv(x22,filters*1,kernel_size=[1,1],activation=activation,stride=1)\n",
    "    \n",
    "    x112=conv(x11,filters*2,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x121=conv(x12,filters*2,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x212=conv(x12,filters*2,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x221=conv(x22,filters*2,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x121=tf.concat([x112,x121],-1)\n",
    "    x212=tf.concat([x212,x221],-1)\n",
    "    x1213=dconv(x121,filters*2,kernel_size=[1,1],activation=activation,stride=1)\n",
    "    x2123=dconv(x212,filters*2,kernel_size=[1,1],activation=activation,stride=1)\n",
    "    \n",
    "    x1212=conv(x121,filters*4,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x2121=conv(x212,filters*4,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x1212=tf.concat([x1212,x2121],-1)\n",
    "    \n",
    "    x121=dconv(x1212,filters*2,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x212=dconv(x1212,filters*2,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x121=tf.concat([x121,x1213],-1)\n",
    "    x212=tf.concat([x212,x2123],-1)\n",
    "    \n",
    "    x11=dconv(x121,filters*1,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x12=dconv(x121,filters*1,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x21=dconv(x212,filters*1,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x22=dconv(x212,filters*1,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x11=tf.concat([x11,x113],-1)\n",
    "    x12=tf.concat([x12,x21,x123],-1)\n",
    "    x22=tf.concat([x22,x223],-1)\n",
    "    \n",
    "    x1=dconv(x11,filters*1,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x1_=dconv(x12,filters*1,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x2=dconv(x12,filters*1,kernel_size=[1,3],stride=(1,3),activation=activation)\n",
    "    x2_=dconv(x22,filters*1,kernel_size=[3,1],stride=(3,1),activation=activation)\n",
    "    x1=tf.concat([x1,x1_,x13],-1)\n",
    "    x2=tf.concat([x2,x2_,x23],-1)\n",
    "    \n",
    "    x=dconv(x1,int(filters*1),kernel_size=[1,3],stride=(1,3),activation=line,norm=False)\n",
    "    x_=dconv(x2,int(filters*1),kernel_size=[3,1],stride=(3,1),activation=line,norm=False)\n",
    "\n",
    "    x=tf.concat([x3,x,x_],-1)\n",
    "    x=activation(bn(x))\n",
    "    x=dconv(x,int(filters*1),kernel_size=[1,1],activation=line,stride=1,norm=False)\n",
    "    return x\n",
    "\n",
    "def check(out,q_):\n",
    "    mask=np.sum(out*(q_!=0)==q_,(1,2))==81\n",
    "    mask=mask*(np.sum(np.sort(out,axis=-1)==np.arange(1,10),(1,2))==81)\n",
    "    mask=mask*(np.sum(np.transpose(np.sort(out,axis=-2),[0,2,1])==np.arange(1,10),(1,2))==81)\n",
    "    mask=mask*(np.sum(np.sort(np.reshape(np.transpose(np.reshape(out,[-1,3,3,3,3]),[0,1,3,2,4]),[-1,9,9]\n",
    "                                        ),axis=-1)==np.arange(1,10),(1,2))==81)\n",
    "    return (1-mask).astype(np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdconv0(net):\n",
    "    reuse=len([t for t in tf.global_variables() if t.name.startswith('step0')])>0\n",
    "    with tf.variable_scope('step0',reuse=reuse):\n",
    "        net=sdconv(net,256)\n",
    "    return net\n",
    "\n",
    "def sdconv1(net):\n",
    "    reuse=len([t for t in tf.global_variables() if t.name.startswith('step1')])>0\n",
    "    with tf.variable_scope('step1',reuse=reuse):\n",
    "        net=sdconv(net,256)\n",
    "    return net\n",
    "\n",
    "def sdconv2(net):\n",
    "    reuse=len([t for t in tf.global_variables() if t.name.startswith('step2')])>0\n",
    "    with tf.variable_scope('step2',reuse=reuse):\n",
    "        net=sdconv(net,256)\n",
    "    return net\n",
    "\n",
    "def sdconv3(net):\n",
    "    reuse=len([t for t in tf.global_variables() if t.name.startswith('step3')])>0\n",
    "    with tf.variable_scope('step3',reuse=reuse):\n",
    "        net=sdconv(net,256)\n",
    "    return net\n",
    "\n",
    "def sdconv4(net):\n",
    "    reuse=len([t for t in tf.global_variables() if t.name.startswith('step4')])>0\n",
    "    with tf.variable_scope('step4',reuse=reuse):\n",
    "        net=sdconv(net,256)\n",
    "    return net\n",
    "\n",
    "def sdconv5(net):\n",
    "    reuse=len([t for t in tf.global_variables() if t.name.startswith('step5')])>0\n",
    "    with tf.variable_scope('step5',reuse=reuse):\n",
    "        net=sdconv(net,256)\n",
    "    return net\n",
    "\n",
    "\n",
    "def sdconv6(net):\n",
    "    reuse=len([t for t in tf.global_variables() if t.name.startswith('step6')])>0\n",
    "    with tf.variable_scope('step6',reuse=reuse):\n",
    "        net=sdconv(net,256)\n",
    "    return net\n",
    "\n",
    "def sdconv7(net):\n",
    "    reuse=len([t for t in tf.global_variables() if t.name.startswith('step7')])>0\n",
    "    with tf.variable_scope('step7',reuse=reuse):\n",
    "        net=sdconv(net,256)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,9,9,10])\n",
    "net0=dconv(x,256,kernel_size=[1,1],activation=line,stride=1,norm=False)\n",
    "\n",
    "for i in range(8):\n",
    "    exec('net{} = sdconv{}(net{})'.format(i+1,i,i))\n",
    "    for _ in range(3):\n",
    "        exec('net{} = sdconv{}(net{})'.format(i+1,i,i+1))\n",
    "\n",
    "net = net8[:,:,:,-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver=tf.train.Saver(tf.trainable_variables())\n",
    "saver.restore(sess,r'save\\log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start=time.time()\n",
    "# delay=0\n",
    "q=np.load(r'dataset\\question.npy')\n",
    "# q=q[np.sum(q>0,(1,2))==17]\n",
    "lenq=len(q)\n",
    "unsolve=np.sum(q>0,(1,2))\n",
    "show=[]\n",
    "solve=[]\n",
    "while(len(q)>0):\n",
    "    wronglist=np.array(unsolve)\n",
    "    unsolve=[]\n",
    "    qlist=q\n",
    "    q=[]\n",
    "    for i in range(0,len(qlist),128):\n",
    "        q_=qlist[i:i+128]\n",
    "        feed=(np.reshape(q_,[-1,9,9,1])==np.arange(0,10)).astype(np.float32)\n",
    "        wrong=wronglist[i:i+128]\n",
    "        out=sess.run(net,feed_dict={x:feed})\n",
    "        mask=check(np.argmax(out,-1)+1,q_)\n",
    "        solve.extend(wrong[(1-mask).astype(np.bool)])\n",
    "        wrong=wrong[mask]\n",
    "        n=np.max(out,-1)*(np.array(q_)==0)\n",
    "        n=((n==np.max(n,(1,2),keepdims=True))*(np.argmax(out,-1)+1)+q_)[mask]\n",
    "        mask=np.sum(n>1,(1,2))<81\n",
    "        q.extend(n[mask])\n",
    "        unsolve.extend(wrong[mask])\n",
    "#         time.sleep(0.5)\n",
    "#         delay+=1\n",
    "    show.append([np.sum(np.array(solve)==_) for _ in range(17,35)])\n",
    "#     print(len(solve),len(unsolve))\n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)\n",
    "print('%fms each question'%((time_end-time_start)/lenq))\n",
    "print('accuracy={}'.format(len(solve)/lenq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start=time.time()\n",
    "# delay=0\n",
    "q=np.load(r'dataset\\testq.npy')\n",
    "# q=q[np.sum(q>0,(1,2))==17]\n",
    "lenq=len(q)\n",
    "unsolve=np.sum(q>0,(1,2))\n",
    "show=[]\n",
    "solve=[]\n",
    "while(len(q)>0):\n",
    "    wronglist=np.array(unsolve)\n",
    "    unsolve=[]\n",
    "    qlist=q\n",
    "    q=[]\n",
    "    for i in range(0,len(qlist),128):\n",
    "        q_=qlist[i:i+128]\n",
    "        feed=(np.reshape(q_,[-1,9,9,1])==np.arange(0,10)).astype(np.float32)\n",
    "        wrong=wronglist[i:i+128]\n",
    "        out=sess.run(net,feed_dict={x:feed})\n",
    "        mask=check(np.argmax(out,-1)+1,q_)\n",
    "        solve.extend(wrong[(1-mask).astype(np.bool)])\n",
    "        wrong=wrong[mask]\n",
    "        n=np.max(out,-1)*(np.array(q_)==0)\n",
    "        n=((n==np.max(n,(1,2),keepdims=True))*(np.argmax(out,-1)+1)+q_)[mask]\n",
    "        mask=np.sum(n>1,(1,2))<81\n",
    "        q.extend(n[mask])\n",
    "        unsolve.extend(wrong[mask])\n",
    "#         time.sleep(0.5)\n",
    "#         delay+=1\n",
    "    show.append([np.sum(np.array(solve)==_) for _ in range(17,35)])\n",
    "#     print(len(solve),len(unsolve))\n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)\n",
    "print('%fms each question'%((time_end-time_start)/lenq))\n",
    "print('accuracy={}'.format(len(solve)/lenq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start=time.time()\n",
    "# delay=0\n",
    "q=np.load(r'dataset\\validq.npy')\n",
    "# q=q[np.sum(q>0,(1,2))==17]\n",
    "lenq=len(q)\n",
    "unsolve=np.sum(q>0,(1,2))\n",
    "show=[]\n",
    "solve=[]\n",
    "while(len(q)>0):\n",
    "    wronglist=np.array(unsolve)\n",
    "    unsolve=[]\n",
    "    qlist=q\n",
    "    q=[]\n",
    "    for i in range(0,len(qlist),128):\n",
    "        q_=qlist[i:i+128]\n",
    "        feed=(np.reshape(q_,[-1,9,9,1])==np.arange(0,10)).astype(np.float32)\n",
    "        wrong=wronglist[i:i+128]\n",
    "        out=sess.run(net,feed_dict={x:feed})\n",
    "        mask=check(np.argmax(out,-1)+1,q_)\n",
    "        solve.extend(wrong[(1-mask).astype(np.bool)])\n",
    "        wrong=wrong[mask]\n",
    "        n=np.max(out,-1)*(np.array(q_)==0)\n",
    "        n=((n==np.max(n,(1,2),keepdims=True))*(np.argmax(out,-1)+1)+q_)[mask]\n",
    "        mask=np.sum(n>1,(1,2))<81\n",
    "        q.extend(n[mask])\n",
    "        unsolve.extend(wrong[mask])\n",
    "#         time.sleep(0.5)\n",
    "#         delay+=1\n",
    "    show.append([np.sum(np.array(solve)==_) for _ in range(17,35)])\n",
    "#     print(len(solve),len(unsolve))\n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)\n",
    "print('%fms each question'%((time_end-time_start)/lenq))\n",
    "print('accuracy={}'.format(len(solve)/lenq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
